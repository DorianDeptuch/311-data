# flake8: noqa
"""first migration

Revision ID: 72973ee94bac
Revises: 
Create Date: 2020-08-28 08:40:00.851112

"""
import os
from os.path import join, dirname
import gzip
import csv

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

DATA_FOLDER = join(dirname(__file__), '../seeds/')


# revision identifiers, used by Alembic.
revision = '72973ee94bac'
down_revision = None
branch_labels = None
depends_on = None


# TODO: need to check if these tables exist and pass if they do
def upgrade():

    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('metadata',
        sa.Column('last_pulled', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True)
    )

    requests_table = op.create_table('requests',
        sa.Column('srnumber', sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column('createddate', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
        sa.Column('closeddate', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
        sa.Column('_daystoclose', sa.REAL(), autoincrement=False, nullable=True),
        sa.Column('updateddate', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
        sa.Column('servicedate', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
        sa.Column('requesttype', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('requestsource', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('actiontaken', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('owner', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('status', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('createdbyuserorganization', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('mobileos', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('anonymous', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('assignto', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('latitude', postgresql.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
        sa.Column('longitude', postgresql.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
        sa.Column('addressverified', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('approximateaddress', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('address', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('housenumber', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('direction', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('streetname', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('suffix', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('zipcode', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('location', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
        sa.Column('apc', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('cd', sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column('cdmember', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('nc', sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column('ncname', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('policeprecinct', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('tbmpage', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('tbmcolumn', sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column('tbmrow', sa.INTEGER(), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint('srnumber', name='requests_pkey')
    )
    # ### end Alembic commands ###

    # seed the database during testing
    if os.getenv("TESTING"):
        with open(DATA_FOLDER + 'requests.csv') as f:
            reader = csv.DictReader(f)

            # TODO: is there a better way?
            # Empty String to None Conversion
            conv_list = []
            conv = lambda i : i or None

            for row in reader:
                for k, v in row.items():
                    row[k] = conv(v)
                conv_list.append(row)

            op.bulk_insert(requests_table, conv_list)

        op.execute("insert into metadata \
            select max(updateddate) from requests")


def downgrade():

    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('requests')
    op.drop_table('metadata')
    # ### end Alembic commands ###
